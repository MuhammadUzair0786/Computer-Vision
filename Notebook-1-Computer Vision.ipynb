{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce24195f",
   "metadata": {},
   "source": [
    "# 1. Read and Show Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0764eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58db207",
   "metadata": {},
   "source": [
    "## Image Read and Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb891ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\boat.jpg') # read image\n",
    "cv2.imshow('Boat Image',img) # show image\n",
    "cv2.waitKey(10000)  # image frame wait time-ms and 0 pass keyboard any key press\n",
    "# cv2.destroyAllWindows()  # all window close\n",
    "cv2.destroyWindow('Boat Image')  # only one window close give particular window name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f39b2a",
   "metadata": {},
   "source": [
    "## Image Multiple Window Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626f8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\boat.jpg') # read image\n",
    "cv2.imshow('Boat Image',img) # show image\n",
    "cv2.imshow('Boat Image',img) # show image\n",
    "cv2.waitKey(0)  # image frame wait time-ms and 0 pass keyboard any key press\n",
    "cv2.destroyAllWindows()  # all window close\n",
    "# cv2.destroyWindow()  # only one window close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0babac",
   "metadata": {},
   "source": [
    "## Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab21936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\cat.jpg') # read image\n",
    "\n",
    "#Resize image width ,height\n",
    "img =cv2.resize(img,(500,500))\n",
    "\n",
    "cv2.imshow('Cat Image',img) # show image\n",
    "cv2.waitKey(0)  # image frame wait time-ms and 0 pass keyboard any key press\n",
    "# cv2.destroyAllWindows()  # all window close\n",
    "cv2.destroyWindow('Cat Image')  # only one window close give particular window name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df93e81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 1, 2, 3],\n",
       "       [1, 2, 3, 1, 2, 3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "v =np.array([[1,2,3,1,2,3],[1,2,3,1,2,3]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73128922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  5  22  35]\n",
      "  [  7  24  37]\n",
      "  [ 10  27  40]\n",
      "  ...\n",
      "  [184 181 166]\n",
      "  [184 181 166]\n",
      "  [184 181 166]]\n",
      "\n",
      " [[  8  25  38]\n",
      "  [  9  26  39]\n",
      "  [  9  28  41]\n",
      "  ...\n",
      "  [184 181 166]\n",
      "  [184 181 166]\n",
      "  [184 181 166]]\n",
      "\n",
      " [[ 13  30  43]\n",
      "  [ 12  31  44]\n",
      "  [ 12  31  46]\n",
      "  ...\n",
      "  [184 181 166]\n",
      "  [184 181 166]\n",
      "  [184 181 166]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  9  14  17]\n",
      "  [  4   9  12]\n",
      "  [  9  14  17]\n",
      "  ...\n",
      "  [156 158 158]\n",
      "  [156 158 158]\n",
      "  [156 158 158]]\n",
      "\n",
      " [[ 22  27  30]\n",
      "  [  5  10  13]\n",
      "  [  9  14  17]\n",
      "  ...\n",
      "  [156 158 158]\n",
      "  [156 158 158]\n",
      "  [156 158 158]]\n",
      "\n",
      " [[ 40  45  48]\n",
      "  [ 10  15  18]\n",
      "  [ 10  15  18]\n",
      "  ...\n",
      "  [156 158 158]\n",
      "  [156 158 158]\n",
      "  [156 158 158]]]\n"
     ]
    }
   ],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\cat.jpg') # read image\n",
    "print(img) #RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d883929",
   "metadata": {},
   "source": [
    "# 2. Show Multiple Image and Slide Show\n",
    "### Horizontal and Vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d784790",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg')\n",
    "\n",
    "#Resize image width ,height\n",
    "img =cv2.resize(img,(200,200))\n",
    "\n",
    "#Show horizontal multiple image in one frame\n",
    "h =np.hstack((img,img))\n",
    "\n",
    "#Show vertical multiple image in one frame\n",
    "v =np.vstack((h,h))\n",
    "\n",
    "cv2.imshow('Lion Image',v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a57d3",
   "metadata": {},
   "source": [
    "## Slide Image Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104825c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boat.jpg',\n",
       " 'cat.jpg',\n",
       " 'chair.jpg',\n",
       " 'clock.jpg',\n",
       " 'dog.jpg',\n",
       " 'elephant.jpg',\n",
       " 'fan.jpg',\n",
       " 'Honda Civic.jpg',\n",
       " 'laptop.jpg',\n",
       " 'lion.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# show all images with help of os\n",
    "list_name =os.listdir(r'E:\\Computer-Vision\\Images')\n",
    "list_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9901d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list_name:\n",
    "    path ='E:\\\\Computer-Vision\\\\Images'\n",
    "    img_name = path + '\\\\' + name \n",
    "    img = cv2.imread(img_name)\n",
    "    img =cv2.resize(img,(200,200))\n",
    "    cv2.imshow('Different Images',img)\n",
    "    cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a87f80",
   "metadata": {},
   "source": [
    "# 3. Image imread Function (RGB,grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741ea1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is used for RGB color image flag is 1\n",
    "import cv2\n",
    "img = cv2.imread(r'E:\\Computer-Vision\\Images\\clock.jpg', 1)\n",
    "img = cv2.resize(img,(200,200))\n",
    "cv2.imshow(\"RGB Image flag = 1\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639477ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is used for grayscale image flag is 0\n",
    "import cv2\n",
    "img = cv2.imread(r'E:\\Computer-Vision\\Images\\clock.jpg', 0)\n",
    "img = cv2.resize(img,(200,200))\n",
    "cv2.imshow(\"Grayscale Image flag = 0\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae2344",
   "metadata": {},
   "source": [
    "# 4. Text Over a Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d0019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e7c383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get =cv2.imread(r'E:\\Computer-Vision\\Images\\clock.jpg', -1)  # -1 is used for unchanged image\n",
    "img_get =cv2.resize(img_get,(500,600))\n",
    "\n",
    "# Draw text on image parameters\n",
    "img =img_get\n",
    "text ='Clock Image' # text to be added\n",
    "org = (150, 50)  # position of text\n",
    "fontFace = cv2.FONT_HERSHEY_DUPLEX # font type\n",
    "fontscale = 1 # font scale\n",
    "color = (0, 255, 0)  # BGR color format\n",
    "thickness = 2  # thickness of text\n",
    "lineType =cv2.LINE_8 # line type\n",
    "bottomLeftOrigin = False  # text origin\n",
    "\n",
    "\n",
    "\n",
    "txt =cv2.putText(img, text, org, fontFace, fontscale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    "cv2.imshow('Clock Image',img_get) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173439ab",
   "metadata": {},
   "source": [
    "# 5. Draw Line and Rectangle on Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfd2d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg', -1)  # -1 is used for unchanged image\n",
    "img_get =cv2.resize(img_get,(400,400))\n",
    "\n",
    "# Draw line on image change parameters\n",
    "img =cv2.line(img_get, pt1=(200, 100),pt2= (300 , 100), color =(255, 0, 0), thickness=4,lineType =4)  # line start point, end point, color, thickness\n",
    "\n",
    "cv2.imshow('Lion Image',img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg', -1)  # -1 is used for unchanged image\n",
    "img_get =cv2.resize(img_get,(400,400))\n",
    "\n",
    "# Draw text on image parameters\n",
    "img =img_get\n",
    "text ='lion' # text to be added\n",
    "org = (170, 25)  # position of text\n",
    "fontFace = 2 # font type\n",
    "fontscale = 1 # font scale\n",
    "color = (0, 0, 255)  # BGR color format\n",
    "thickness = 2  # thickness of text\n",
    "lineType = 16 # line type\n",
    "bottomLeftOrigin = False  # text origin\n",
    "\n",
    "txt =cv2.putText(img, text, org, fontFace, fontscale, color, thickness, lineType, bottomLeftOrigin)\n",
    "\n",
    " \n",
    "# Draw Rectangle on image change parameters\n",
    "img =cv2.rectangle(img_get, pt1=(170, 30),pt2= (320 , 300), color =(0, 255, 0), thickness=2,lineType =16)  # line start point, end point, color, thickness\n",
    "\n",
    "cv2.imshow('Lion Image',img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f87a57",
   "metadata": {},
   "source": [
    "# 6. Draw Circle and Elllipse On Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c8e1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get =cv2.imread(r'E:\\Computer-Vision\\Images\\dog.jpg', -1)  # -1 is used for unchanged image\n",
    "img_get =cv2.resize(img_get,(400,400))\n",
    "\n",
    "# Draw circle on image change parameters if thickness =-1 then circle is filled\n",
    "img =cv2.circle(img =img_get, center=(300, 100), radius=65, color=(0, 0, 255), thickness=2, lineType=16)  # center point, radius, color, thickness\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Dog Image',img_get) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "efef136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_get =cv2.imread(r'E:\\Computer-Vision\\Images\\dog.jpg', -1)  # -1 is used for unchanged image\n",
    "img_get =cv2.resize(img_get,(400,400))\n",
    "\n",
    "\n",
    "# write text on image\n",
    "txt_img =cv2.putText(img_get, 'Dog', (250, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "# Draw Ellipsis on image change parameters if thickness =-1 then circle is filled\n",
    "img =cv2.ellipse(img =img_get, center=(305, 115), axes =(35,60), \n",
    "                 angle =10, startAngle =0, endAngle =360,\n",
    "                 color=(0, 0, 255), thickness=2,\n",
    "                 lineType=16)  # center point , color, thickness\n",
    "\n",
    "\n",
    "cv2.imshow('Dog Image',img_get) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb519d57",
   "metadata": {},
   "source": [
    "# 7. Arithmetic Operation on Image using Opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8b8ea2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg', -1)  # -1 is used for unchanged image\n",
    "img2 =cv2.imread(r'E:\\Computer-Vision\\Images\\cat.jpg', -1)  # -1 is used for unchanged image\n",
    "\n",
    "img1 =cv2.resize(img1,(400,400))\n",
    "img2 =cv2.resize(img2,(400,400))\n",
    "\n",
    "# AddWeighted two images \n",
    "img_add = cv2.addWeighted(img1,1, img2, 0.5,1)  # add two images change parameters\n",
    "cv2.imshow('lion and Cat Image Add',img_add)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "36eda822",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg', -1)  # -1 is used for unchanged image\n",
    "img2 =cv2.imread(r'E:\\Computer-Vision\\Images\\cat.jpg', -1)  # -1 is used for unchanged image\n",
    "\n",
    "img1 =cv2.resize(img1,(400,400))\n",
    "img2 =cv2.resize(img2,(400,400))\n",
    "\n",
    "# AddWeighted two images \n",
    "img_add = cv2.subtract(img1, img2)  # subtract two images\n",
    "cv2.imshow('lion and Cat Image Add',img_add)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276b658",
   "metadata": {},
   "source": [
    "# 8. Edge Detection using OpenCV(Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a2b5d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300, 3)\n",
      "(300, 300)\n"
     ]
    }
   ],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Uzair.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(img,(300,300))\n",
    "print(img.shape)  # shape of image\n",
    "\n",
    "new_img =cv2.Canny(img,100,200,apertureSize =5,L2gradient=True)  # Edge detection using Canny method change threshold values for clear edges\n",
    "print(new_img.shape)  # shape of new image after edge detection\n",
    "\n",
    "cv2.imshow('Orginal Image',img)\n",
    "cv2.imshow('Edge Detection Image',new_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332f900",
   "metadata": {},
   "source": [
    "# 9.Image Scaling, Rotating using OpenCV  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62b429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "res_img =cv2.resize(img,(300,400))\n",
    "\n",
    "cv2.imshow('Orginal Image',org_img)\n",
    "cv2.imshow('Scaling Image',res_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "res_img =cv2.resize(img,(300,400))\n",
    "org_img = cv2.resize(org_img, (300, 400))  # Resize original image to match resized image dimensions\n",
    "\n",
    "# Rotate the resized image by 45 degrees\n",
    "w,h =res_img.shape[0],res_img.shape[1]  # Get width and height of resized image\n",
    "m = cv2.getRotationMatrix2D(center=(w/2,h/2), angle=45,scale =1)  # Get rotation matrix for image rotation\n",
    "new_img = cv2.warpAffine(res_img, m, (h, w))  # Apply rotation to the resized image\n",
    "\n",
    "# Stack original and rotated images horizontally\n",
    "h =np.hstack((org_img,new_img))  \n",
    "cv2.imshow('Orginal Image and Rotate Image',h)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f8c0",
   "metadata": {},
   "source": [
    "# 10. Image bluring using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "res_img =cv2.resize(img,(300,400))\n",
    "org_img = cv2.resize(org_img, (300, 400))  # Resize original image to match resized image dimensions\n",
    "\n",
    "# Blurring the resized image using GaussianBlur\n",
    "# Three Type of blurring methods (Gaussian, Median, Bilateral)\n",
    "\n",
    "blurred_img = cv2.GaussianBlur(res_img, (15, 15), 0)  # Apply Gaussian blur with a kernel size of 15x15\n",
    "# m_blurred_img = cv2.medianBlur(blurred_img, 15)  # Apply median blur with a kernel size of 15\n",
    "# b_blurred_img =cv2.bilateralFilter(blurred_img, d=15, sigmaColor=75, sigmaSpace=75)  # Apply bilateral filter with specified parameters\n",
    "\n",
    "\n",
    "# Stack original and rotated images horizontally\n",
    "g =np.hstack((org_img,blurred_img))  \n",
    "cv2.imshow('Orginal Image and Rotate Image',g)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b9fcb",
   "metadata": {},
   "source": [
    "# 11.imwrite method using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db1be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "res_img =cv2.resize(org_img,(300,400))\n",
    "\n",
    "\n",
    "h =np.hstack((res_img,res_img)) \n",
    "v =np.vstack((h,h))  \n",
    "\n",
    " # imwrite function Save the image to a file\n",
    "imwrite_img =cv2.imwrite('imwrite image.jpg', v) \n",
    "\n",
    "cv2.imshow('ImWrite Funtion',v)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92453bc2",
   "metadata": {},
   "source": [
    "# 12.MakeBorder using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(org_img,(300,400))\n",
    "\n",
    "# Draw Border side of Images\n",
    "border_img =cv2.copyMakeBorder(img,20,20,20,20, borderType=cv2.BORDER_CONSTANT, value=2)\n",
    "\n",
    "\n",
    "cv2.imshow('Border Funtion',border_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1cd1b",
   "metadata": {},
   "source": [
    "# 13.Play a video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0504902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "cap =cv2.VideoCapture(r'E:\\Computer-Vision\\Images\\Video.mp4')\n",
    "\n",
    "# Check if the video is opened successfully  \n",
    "while cap.isOpened():\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        frame =cv2.resize(frame,(500,500))  # Resize video frame\n",
    "        cv2.imshow('Video Frame',frame)\n",
    "        if cv2.waitKey(25) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bab9df",
   "metadata": {},
   "source": [
    "# 14.Capture Video from the Camera using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99d2934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0) # Capture video from the camera\n",
    "\n",
    "while True:\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        frame =cv2.resize(frame,(500,500))  # Resize video frame\n",
    "        cv2.imshow('Camera Video Frame',frame)\n",
    "        if cv2.waitKey(25) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc2790",
   "metadata": {},
   "source": [
    "# 15.Slow and Fast Motion Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8f375d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(r'E:\\Computer-Vision\\Images\\Video.mp4') # Capture video from the camera\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        frame =cv2.resize(frame,(500,500))  # Resize video frame\n",
    "        cv2.imshow('Camera Video Frame',frame)\n",
    "        \n",
    "        # Slow and Fast Motion Video if you want to slow down the video, increase the wait time\n",
    "        # if you want to speed up the video, decrease the wait time\n",
    "        if cv2.waitKey(5) & 0xff == ord('q'): # #fast\n",
    "        # if cv2.waitKey(50) & 0xff == ord('q'): #slow\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf095c94",
   "metadata": {},
   "source": [
    "# 16. Cropping Image or Image Translation using OpenCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e11aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(org_img,(300,400))\n",
    "\n",
    "# Cropping Image or Image Translation using OpenCV\n",
    "m = np.float32([[1, 0, 50], [0, 1, 100]])  # Translation matrix to translate the image by 50 pixels in x and y direction\n",
    "new_img =cv2.warpAffine(img,m,(300,400) )  # Translate the image by 50 pixels in x and y direction\n",
    "\n",
    "cv2.imshow('Orginal Image',img)\n",
    "cv2.imshow('Map Image',m)\n",
    "cv2.imshow('Crop Image',new_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24ead2",
   "metadata": {},
   "source": [
    "# 17.Background subtraction using OpenCV\n",
    "### Agr ham kasi video ma sa chata ha k sirf wohi object detect ho jiski hama zorart ha to usko use karta ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c865089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "cap =cv2.VideoCapture(r'E:\\Computer-Vision\\Images\\Video.mp4')\n",
    "\n",
    "# Create background subtractor object\n",
    "sub_m = cv2.createBackgroundSubtractorMOG2() \n",
    "\n",
    "# Check if the video is opened successfully  \n",
    "while cap.isOpened():\n",
    "    r,frame = cap.read()\n",
    "    if r == True:\n",
    "        frame =cv2.resize(frame,(500,400))  # Resize video frame  \n",
    "        sub_video = sub_m.apply(frame)  \n",
    "        cv2.imshow('Background Subtraction Video Frame',sub_video)\n",
    "        cv2.imshow('Video Frame',frame)\n",
    "        if cv2.waitKey(20) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9a322",
   "metadata": {},
   "source": [
    "# 18.Extract images from video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0a72b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "cap =cv2.VideoCapture(r'E:\\Computer-Vision\\Images\\Video.mp4')\n",
    "\n",
    "c =0\n",
    "# Check if the video is opened successfully  \n",
    "while True:\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        frame =cv2.resize(frame,(500,500))  # Resize video frame\n",
    "        \n",
    "        # Extract images from video using OpenCV\n",
    "        \n",
    "        filename = 'E://Computer-Vision//Images//org_img'+str(c)+'.jpg'  # Create a filename for the extracted image\n",
    "        cv2.imwrite(filename, frame)  # Save the extracted image to the file\n",
    "        cv2.imshow('Extracted Image', frame)\n",
    "        c =c+1  # Increment the counter for the next image filename\n",
    "        cv2.imshow('Video Frame',frame)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(25) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the video capture object\n",
    "\n",
    "cv2.destroyAllWindows() # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9357c9b",
   "metadata": {},
   "source": [
    "# 19. cvtColor method OpenCV (Chnage Color of Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(img,(300,400))\n",
    "\n",
    "# Change Color of Image using cvtColor method OpenCV\n",
    "new_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
    "\n",
    "\n",
    "cv2.imshow('Orginal Image',img)\n",
    "cv2.imshow('Change Color Image',new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae906e35",
   "metadata": {},
   "source": [
    "# 20. Crop Image using OpenCV Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa82967",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(img,(300,400))\n",
    "\n",
    "# Crop Image using OpenCV Python\n",
    "crop =img[50:300,:] \n",
    "\n",
    "cv2.imshow('Orginal Image',img)\n",
    "cv2.imshow('Crop Image',crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf46389",
   "metadata": {},
   "source": [
    "# 21. Flip , Rotate & Transpose using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9520c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Person.jpg', -1)  # -1 is used for unchanged image\n",
    "img =cv2.resize(img,(300,400))\n",
    "\n",
    "# Flip image using OpenCV\n",
    "img_flip =cv2.flip(img,1) # y-axis flip\n",
    "# img_flip =cv2.flip(img,0) # x-axis flip\n",
    "\n",
    "# Rotate Images\n",
    "Rotate_img =cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "# Transpose Image\n",
    "transpose_img = cv2.transpose(img)  # Transpose the image\n",
    "\n",
    "cv2.imshow('Orginal Image',img)\n",
    "cv2.imshow('Flip Image',img_flip)\n",
    "cv2.imshow('Rotate Image',Rotate_img)\n",
    "cv2.imshow('Transpose Image',transpose_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd3528",
   "metadata": {},
   "source": [
    "# 22.Camera Video Record & Saving color & Grayscale a Video using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ebe496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# 1.Record Video from Camera using OpenCV\n",
    "video_record =cv2.VideoWriter_fourcc(*'XVID')  # Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter('output_video.mp4', video_record, 20.0, (640, 480))  # Create VideoWriter object to save the video\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        # 2. flip us lai kia taqa hamri video frame mirror image ban jaye\n",
    "        frame =cv2.flip(frame,1)\n",
    "        # 3. video save\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame =cv2.resize(frame,(500,500)) \n",
    "        cv2.imshow('Camera Video Frame',frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "# 4. Release the video capture object\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf6b50",
   "metadata": {},
   "source": [
    "## Convert Video Into GrayScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# 1.Record Video from Camera using OpenCV\n",
    "video_record =cv2.VideoWriter_fourcc(*'XVID')  # Define the codec and create VideoWriter object\n",
    "# Add 0 as a parameter for save grayscale video \n",
    "out = cv2.VideoWriter('gray_output_video.mp4', video_record, 20.0, (640, 480),0)  # Create VideoWriter object to save the video\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        # 1. Convert video frame to grayscale\n",
    "        frame =cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 2. flip us lai kia taqa hamri video frame mirror image ban jaye\n",
    "        frame =cv2.flip(frame,1)\n",
    "        # 3. video save\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame =cv2.resize(frame,(500,500)) \n",
    "        cv2.imshow('Camera Video Frame',frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    "# 4. Release the video capture object\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c496d4",
   "metadata": {},
   "source": [
    "# 23. Filter Color with OpenCV (Live Object Filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef3a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "def liveObjectFilter():\n",
    "    pass\n",
    "cv2.namedWindow('Live Object Filter')  # Create a window to display the video feed\n",
    "cv2.createTrackbar('lb', 'Live Object Filter', 0, 255, liveObjectFilter)  # Create a trackbar for Red channel\n",
    "cv2.createTrackbar('lg', 'Live Object Filter', 0, 255, liveObjectFilter)\n",
    "cv2.createTrackbar('lr', 'Live Object Filter', 0, 255, liveObjectFilter)\n",
    "\n",
    "\n",
    "cv2.createTrackbar('ub', 'Live Object Filter', 255, 255, liveObjectFilter)\n",
    "cv2.createTrackbar('ug', 'Live Object Filter', 255, 255, liveObjectFilter)\n",
    "cv2.createTrackbar('ur', 'Live Object Filter', 255, 255, liveObjectFilter)\n",
    "\n",
    "while cap.isOpened():\n",
    "    r, frame = cap.read()\n",
    "    if r == True:\n",
    "        img = cv2.resize(frame, (500, 500))  # Resize video frame\n",
    "        hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # Convert the frame to HSV color space\n",
    "        \n",
    "        \n",
    "        # Get the values from the trackbars\n",
    "        lb = cv2.getTrackbarPos('lb', 'Live Object Filter')\n",
    "        lg = cv2.getTrackbarPos('lg', 'Live Object Filter')\n",
    "        lr = cv2.getTrackbarPos('lr', 'Live Object Filter')\n",
    "        \n",
    "        ub = cv2.getTrackbarPos('ub', 'Live Object Filter')\n",
    "        ug = cv2.getTrackbarPos('ug', 'Live Object Filter')\n",
    "        ur = cv2.getTrackbarPos('ur', 'Live Object Filter')\n",
    "        \n",
    "        # Create lower and upper bounds for color filtering\n",
    "        lower_bound = np.array([lb, lg, lr])\n",
    "        upper_bound = np.array([ub, ug, ur])\n",
    "        \n",
    "        # Apply color filtering\n",
    "        mask = cv2.inRange(hsv_img, lower_bound, upper_bound)\n",
    "        res =cv2.bitwise_and(img, img, mask=mask)\n",
    "        \n",
    "        # Show the original frame and the mask\n",
    "        cv2.imshow('Filtered Frame', res)\n",
    "        cv2.imshow('Original Frame', img)\n",
    "        cv2.imshow('Mask', mask)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()  # Release the video capture object\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92155aef",
   "metadata": {},
   "source": [
    "# 24.Perspective Transformation OpenCV(Us k zaryia ham apna cam Scanner bana sakta ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f84d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\cam_scanner_img.jpg', -1)\n",
    "img =cv2.resize(img,(500,500))\n",
    "\n",
    "# Perspective Transformation OpenCV\n",
    "cv2.circle(img,(189,31),4,(0,0,255),-1)  # Draw a circle at the specified coordinates with a radius of 4 pixels and color red\n",
    "cv2.circle(img,(1119,37),4,(0,0,255),-1)  # Draw a circle at the specified coordinates with a radius of 4 pixels and color red\n",
    "cv2.circle(img,(143,661),4,(0,0,255),-1)  # Draw a circle at the specified coordinates with a radius of 4 pixels and color red\n",
    "cv2.circle(img,(1091,707),4,(0,0,255),-1)  # Draw a circle at the specified coordinates with a radius of 4 pixels and color red\n",
    "\n",
    "w,h =(400,400)\n",
    "mask=cv2.getPerspectiveTransform(np.float32([[189,31],[1119,37],[143,661],[1091,707]]),np.float32([[0,0],[w,0],[0,h],[w,h]]))\n",
    "new_img =cv2.warpPerspective(img,mask,(w,h))  # Apply perspective transformation to the image using the transformation matrix\n",
    "\n",
    "\n",
    "cv2.imshow('Original Image', img) \n",
    "cv2.imshow('New Image', new_img) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beabda0",
   "metadata": {},
   "source": [
    "# 25. Simple Thresholding(Use for Background Remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "455d807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\lion.jpg', -1)\n",
    "img =cv2.resize(img,(300,300))\n",
    "\n",
    "# Thresholding Image \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_,th = cv2.threshold(img,100,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('Threshold Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86128a0",
   "metadata": {},
   "source": [
    "# 27.Otsu's Binarization Threshold OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad91e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\apple_leaf.jpg', -1)\n",
    "img =cv2.resize(img,(300,300))\n",
    "\n",
    "# Thresholding Image \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " # Otsu's binarization thresholding method\n",
    "_,th = cv2.threshold(img,100,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) \n",
    "\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('Threshold Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11780b00",
   "metadata": {},
   "source": [
    "# 28.Image Contours\n",
    "#### Contours trace the boundaries of objects in an image to detect their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babcc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\apple_leaf.jpg', -1)\n",
    "img =cv2.resize(img,(300,300))\n",
    "\n",
    "# Thresholding Image \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "r,th = cv2.threshold(img,100,255,cv2.THRESH_BINARY) \n",
    "c,h =cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours in the thresholded image\n",
    "new_img = cv2.drawContours(img, c, -1, (0, 255, 0), 2)  # Draw contours on the original image\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('contours Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f304b351",
   "metadata": {},
   "source": [
    "# 29.Contour Moments and ConvexHull\n",
    "##### Contour Moments help calculate object properties like area, centroid, and orientation.\n",
    "(Use: For shape analysis and object tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4423d5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89401.0, 1819.0, 1373.0, 2315.0, 1196.0, 1069.0, 1778.5, 1252.5, 1465.5, 1379.0, 1480.0, 1286.0, 1447.0, 1779.0, 1595.0, 988.0, 1248.0]\n"
     ]
    }
   ],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Shapes Image.jpg', -1)\n",
    "img =cv2.resize(img,(300,300))\n",
    "\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, th =cv2.threshold(gry,220,255,cv2.THRESH_BINARY)\n",
    "cnt,hir = cv2.findContours(th, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img = cv2.drawContours(img, cnt, -1, (0, 0, 255), 2)  # Draw contours on the original image\n",
    "\n",
    "ar =[]\n",
    "# Find center with help of moments\n",
    "for c in cnt:\n",
    "    m = cv2.moments(c)  # Calculate moments of the contour\n",
    "    if m['m00'] != 0:  # Check if the area is not zero to avoid division by zero\n",
    "        x = int(m['m10'] / m['m00'])  # Calculate x coordinate of the center\n",
    "        y = int(m['m01'] / m['m00'])  # Calculate y coordinate of the center\n",
    "        cv2.circle(img, (x, y), 3, (255, 0, 0), -1)  # Draw a circle at the center of the contour\n",
    "        a =cv2.contourArea(c)\n",
    "        ar.append(a)\n",
    "        \n",
    "print(ar)  # Print the areas of the contours        \n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('contours Moment Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23a3ba",
   "metadata": {},
   "source": [
    "# ConvexHull (ConvexHull is used to detect main area of object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b2ab104",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Shapes Image.jpg', -1)\n",
    "img =cv2.resize(img,(300,300))\n",
    "\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, th =cv2.threshold(gry,220,255,cv2.THRESH_BINARY)\n",
    "cnt,hir = cv2.findContours(th, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "img = cv2.drawContours(img, cnt, -1, (0, 0, 255), 2)  # Draw contours on the original image\n",
    "\n",
    "\n",
    "\n",
    "# Find center with help of moments-------------------\n",
    "for c in cnt:\n",
    "    m = cv2.moments(c)  # Calculate moments of the contour\n",
    "    if m['m00'] != 0:  # Check if the area is not zero to avoid division by zero\n",
    "        x = int(m['m10'] / m['m00'])  # Calculate x coordinate of the center\n",
    "        y = int(m['m01'] / m['m00'])  # Calculate y coordinate of the center\n",
    "        cv2.circle(img, (x, y), 3, (255, 0, 0), -1)  # Draw a circle at the center of the contour\n",
    "        #----------------------------------\n",
    "        \n",
    "        # Convex Hull code ---------------------\n",
    "        ep =0.0\n",
    "        1 * cv2.arcLength(c,True)\n",
    "        d =cv2.approxPolyDP(c,ep,True)\n",
    "        h =cv2.convexHull(d)  # Calculate the convex hull of the contour\n",
    "        x,y,w,h =cv2.boundingRect(h)  # Get the bounding rectangle of the convex hull\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h),(0,255,0),2)  # Draw a rectangle around the convex hull\n",
    "        #---------------------------------------\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('convexHull Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290fb78",
   "metadata": {},
   "source": [
    "# 30.Object Detection using Contours by webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17015720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "cv2.namedWindow('Trackbars')  # Create a window to display the trackbars\n",
    "\n",
    "cv2.createTrackbar('th', 'Trackbars', 0, 255, nothing)  # Create a trackbar for Red channel\n",
    "\n",
    "cv2.createTrackbar('lb', 'Trackbars', 0, 255, nothing)\n",
    "cv2.createTrackbar('lg', 'Trackbars', 0, 255, nothing)\n",
    "cv2.createTrackbar('lr', 'Trackbars', 0, 255, nothing)\n",
    "\n",
    "cv2.createTrackbar('hb', 'Trackbars', 255, 255, nothing)\n",
    "cv2.createTrackbar('hg', 'Trackbars', 255, 255, nothing)\n",
    "cv2.createTrackbar('hr', 'Trackbars', 255, 255, nothing)\n",
    "\n",
    "\n",
    "# This code is used to open the camera and apply color filtering using trackbars to adjust the HSV values\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    r,frame =cap.read()\n",
    "    if r == True:\n",
    "        LB = cv2.getTrackbarPos('lb', 'Trackbars')\n",
    "        LG = cv2.getTrackbarPos('lg', 'Trackbars')\n",
    "        LR = cv2.getTrackbarPos('lr', 'Trackbars')\n",
    "        \n",
    "        hB = cv2.getTrackbarPos('hb', 'Trackbars')\n",
    "        hG = cv2.getTrackbarPos('hg', 'Trackbars')\n",
    "        hR = cv2.getTrackbarPos('hr', 'Trackbars')\n",
    "        \n",
    "        lower_limit =np.array([LB,LG,LR])\n",
    "        upper_limit =np.array([hB,hG,hR]) \n",
    "\n",
    "        \n",
    "        frame =cv2.flip(frame,1)\n",
    "        frame =cv2.resize(frame,(400,400))  # Resize video frame\n",
    "        hsv =cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        m =cv2.inRange(hsv,lower_limit,upper_limit)\n",
    "        res =cv2.bitwise_and(frame,frame,mask =m)\n",
    "        fr =cv2.bitwise_not(res)\n",
    "        \n",
    "        thi = cv2.threshold(m,th,255,cv2.THRESH_BINARY)[1]\n",
    "        cnt,hir = cv2.findContours(thi, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        cv2.drawContours(frame, cnt, -1, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        cv2.imshow('thr',thi)\n",
    "        cv2.imshow('Result',res)\n",
    "        cv2.imshow('Mask',m)\n",
    "        cv2.imshow('Video Frame',frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "  #-------------------------------------      \n",
    "        \n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6a069",
   "metadata": {},
   "source": [
    "# 31.Template Matching Using OpenCV\n",
    "##### Template Mattching is used to search single image from multiple object image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "553ec81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\TM-Test_img.png')\n",
    "gry = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "temp =cv2.imread(r'E:\\Computer-Vision\\Images\\TM-test.png')\n",
    "gry1 = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "# template matching method code ----------------\n",
    "w,h =gry1.shape[::-1]\n",
    "res =cv2.matchTemplate(gry,gry1,cv2.TM_CCOEFF_NORMED)\n",
    "thr =0.8\n",
    "l =np.where(res >=thr)\n",
    "for i in zip(*l[::-1]):\n",
    "    cv2.rectangle(img,i,(i[0]+w,i[1]+h),(0,255,0),1)\n",
    "img =cv2.resize(img,(600,500)) \n",
    "#--------------------------------\n",
    "\n",
    "\n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('Template Image', temp)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0873c9",
   "metadata": {},
   "source": [
    "# 32. Hough Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "699d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv2.imread(r'E:\\Computer-Vision\\Images\\Ball Image.png')\n",
    "img =cv2.resize(img,(500,500))\n",
    "gr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gr =cv2.medianBlur(gr,7)  # Apply median blur to the grayscale image\n",
    "gr =cv2.resize(gr,(500,500))  # Resize the grayscale image\n",
    "\n",
    "# Hough Circle Transform method code ----------------\n",
    "circles = cv2.HoughCircles(gr, cv2.HOUGH_GRADIENT, dp=1, minDist=20, param1=85, param2=30, minRadius=0, maxRadius=100)  # Detect circles in the image\n",
    " \n",
    "data =np.uint16(np.around(circles))  # Convert the detected circles to unsigned 16-bit integers\n",
    "\n",
    "for (x,y,r) in data[0,:]:\n",
    "    cv2.circle(img, (x, y), r, (0, 0, 255), 4)  # Draw the circle outline\n",
    "    \n",
    "    \n",
    "cv2.imshow('Orginal Image', img)\n",
    "cv2.imshow('Template Image', gr)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d69a7e",
   "metadata": {},
   "source": [
    "# 33. Grabcut Algorithm for Background Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d527000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(r'E:\\Computer-Vision\\Images\\Honda Civic.jpg')\n",
    "\n",
    "# Create a mask with the same height and width as the image\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "# Create background and foreground models\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "# Define the rectangle coordinates for the region of interest (ROI)\n",
    "# Format: x, y, width, height\n",
    "r = (34, 55, 358-34, 178-55)  # Convert to (x, y, width, height)\n",
    "\n",
    "# Apply GrabCut algorithm\n",
    "cv2.grabCut(img, mask, r, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# Create a mask where background and probable background are 0, and foreground is 1\n",
    "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "# Apply the mask to the original image\n",
    "img_segmented = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "cv2.imshow('GrabCut Image', img_segmented)\n",
    "cv2.imshow('Original Image', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f874b39",
   "metadata": {},
   "source": [
    "# 34. Video Background Removal Using Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a56a300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r'E:\\Computer-Vision\\Images\\Video.mp4')\n",
    "\n",
    "algo1 =cv2.createBackgroundSubtractorKNN()\n",
    "algo2 =cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    r, frame = cap.read()\n",
    "    if r == True:\n",
    "        frame = cv2.resize(frame, (500, 400))\n",
    "        r1 = algo1.apply(frame)\n",
    "        r2 = algo2.apply(frame)\n",
    "        cv2.imshow('KNN', frame)\n",
    "        cv2.imshow('Algo1', r1)\n",
    "        cv2.imshow('Algo2', r2)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2bfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
